#!/bin/bash
# https://www.majlovesreg.one/tag/code/

[ -r "/home/maj/bin/maj-source" ] && source "/home/maj/bin/maj-source"

unique_script

################################################################################

# dir="${HOME}/Desktop/nwt_sl"
dir="/home/share/http-share/nwt_sl"
dir_tmp="${dir}/.for-recode"
processing_prefix='processing-'

dl_api="https://b.jw-cdn.org/apis/pub-media/GETPUBMEDIALINKS"
outfmt="json"
pub="nwt"
format="MP4%2CM4V" # URL encoded, ie: MP4%2CM4V

langs=("SLV" "BVL" "ASL" "SPE" "INI")

parallel_langs=4 # Limits parallel curl requests
parallel_ffmpeg=6 # Limits parallel ffmpeg CPU cores

ff='/usr/bin/ffmpeg'
ff_banner='-hide_banner -loglevel level+warning'
filter="minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1"
ff_opts_post="-y -c:a copy -c:v libx264 -c:s mov_text -crf 20 -preset slow -nostdin -xerror"

################################################################################

process_lang() {

  lang=${1^^} # Uppercase

  dir_lang="${dir}/${pub}_${lang}-60fps"
  [ -d "${dir_lang}" ] || mkdir -p "${dir_lang}"
  cd "${dir_lang}"

  data_full="${dir_lang}/data_full_nwt_${lang}.json"
  [ -s "${data_full}" ] && mv "${data_full}" "${data_full}.prev" && truncate -s 0 "${data_full}"

  for n in {1..66}; do
    echo -n "${lang}_${n} "
    curl -sf "${dl_api}?output=${outfmt}&pub=${pub}&fileformat=${format}&alllangs=0&langwritten=${lang}&txtCMSLang=${lang}&booknum=${n}" >> "${data_full}"
  done

  echo "${lang}_done!"

  data_dl="${dir_lang}/data_dl_nwt_${lang}.csv"
  data_part=$(jq '.files.'${lang}'.MP4[] | select(.label=="720p") | .file | select(.url | endswith(".mp4"))' "${data_full}" 2>/dev/null) && echo "${data_part}" | jq -s . | \
    jq -r 'map({checksum, url}) | (map(keys) | add | unique) as $cols | map(. as $row | $cols | map($row[.])) as $rows | $cols, $rows[] | @csv' > "${data_dl}"
  data_part=$(jq '.files.'${lang}'.M4V[] | select(.label=="720p") | .file | select(.url | endswith(".m4v"))' "${data_full}" 2>/dev/null) && echo "${data_part}" | jq -s . | \
    jq -r 'map({checksum, url}) | (map(keys) | add | unique) as $cols | map(. as $row | $cols | map($row[.])) as $rows | $cols, $rows[] | @csv' | tail -n +2 >> "${data_dl}"
  
  data_processed="${dir_lang}/data_processed_nwt_${lang}.csv"
  [ -f "${data_processed}" ] || touch "${data_processed}"

  data_toprocess="$(mktemp -u --tmpdir $(basename ${0}).XXXXXXXXXX)"

  grep -vFf <(cat "${data_processed}" | cut -d , -f 1) "${data_dl}" > "${data_toprocess}"

  cat "${data_toprocess}" | \
  while read data; do

    url="$(echo ${data} | cut -d , -f 2 | tr -d '"')"
    echo "${url}" | grep -Eq "^https.*(mp4|m4v)$" || continue
    file_save="${dir_lang}/"$(basename "${url}")
    file_save_tmp="${dir_tmp}/"$(basename "${url}")
    file_save_tmp_processing="${dir_tmp}/${processing_prefix}"$(basename "${url}")

    while [ $(pgrep -c ffmpeg) -ge ${parallel_ffmpeg} ]; do
      sleep "1.$(shuf -i 00-99 -n 1)"
    done

    wget -qO "${file_save_tmp}" -o /dev/null "${url}" && \
    nice -n 19 /usr/bin/chrt -i 0 "${ff}" ${ff_banner} -i "${file_save_tmp}" -vf "${filter}" ${ff_opts_post} "${file_save_tmp_processing}" && \
    mv "${file_save_tmp_processing}" "${file_save}" && \
    echo "${data}" >> "${data_processed}" && \
    rm "${file_save_tmp}" &

    sleep "0.$(shuf -i 50-60 -n 1)" # Allow time for wget to write save file, prevent race condition on parallel_ffmpeg count

    while [ $(ls "${dir_tmp}/"* 2>/dev/null | grep -cv "^${dir_tmp}/${processing_prefix}") -ge ${parallel_ffmpeg} ]; do
      sleep "1.$(shuf -i 00-99 -n 1)"
    done
  
  done

  rm "${data_toprocess}"

}

################################################################################

[ -d "${dir}" ] || mkdir -p "${dir}"
cd "${dir}"

[ -d "${dir_tmp}" ] || mkdir -p "${dir_tmp}"
rm -f "${dir_tmp}/"*

for a in ${langs[@]}; do
  
  ( process_lang "${a}" ) &
  [ $(jobs -r -p | wc -l) -ge ${parallel_langs} ] && wait -n

done

wait
echo

beep
